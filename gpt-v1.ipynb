{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "823ce988-1c99-481d-b1bc-943b9587795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import mmap\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import os \n",
    "import tqdm\n",
    "parser = argparse.ArgumentParser(description='This is a demonstration program')\n",
    "#parser.add_argument('-batch_size', type=str, required=True, help=\"Please provide a batch_size\")\n",
    "\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#print(f\"batch_size:{args.batch_size}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)\n",
    "block_size = 16\n",
    "batch_size = 2\n",
    "max_iters = 200\n",
    "learning_rate = 3e-3\n",
    "eval_iters=100\n",
    "n_embd = 200\n",
    "n_head = 4\n",
    "dropout = 0.2\n",
    "n_layer = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9beb9992-8d8a-48b1-bf69-79ea1cf81072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x7f', '\\x80', '\\x81', '\\x82', '\\x83', '\\x84', '\\x88', '\\x8c', '\\x8d', '\\x8f', '\\x90', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97', '\\x98', '\\x99', '\\x9c', '\\x9d', '\\x9f', '¡', '¢', '£', '¤', '¥', '¦', '§', '¨', '©', 'ª', '«', '¬', '\\xad', '®', '¯', '°', '±', '²', '³', '´', 'µ', '¶', '·', '¸', '¹', 'º', '»', '¼', '½', '¾', '¿', 'À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Æ', 'Ç', 'È', 'É', 'Ê', 'Ë', 'Ì', 'Í', 'Î', 'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Ö', '×', 'Ø', 'Ù', 'Ú', 'Û', 'Ü', 'Ý', 'Þ', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', '÷', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'þ', 'ÿ', 'Ā', 'ā', 'Ă', 'ă', 'ą', 'Ć', 'ć', 'ĉ', 'Č', 'č', 'ď', 'Đ', 'đ', 'ē', 'ĕ', 'ė', 'ę', 'ě', 'Ĝ', 'ĝ', 'Ğ', 'ğ', 'ġ', 'ĥ', 'Ħ', 'ħ', 'ĩ', 'Ī', 'ī', 'ĭ', 'į', 'İ', 'ı', 'ĵ', 'ķ', 'ĸ', 'ĺ', 'ľ', 'Ł', 'ł', 'ń', 'ņ', 'ň', 'ŋ', 'Ō', 'ō', 'ŏ', 'Ő', 'ő', 'Œ', 'œ', 'Ř', 'ř', 'Ś', 'ś', 'ŝ', 'Ş', 'ş', 'Š', 'š', 'Ţ', 'ţ', 'ť', 'ũ', 'ū', 'ŭ', 'ů', 'ű', 'ų', 'ŵ', 'Ÿ', 'ź', 'Ż', 'ż', 'Ž', 'ž', 'ƒ', 'ơ', 'ư', 'ǀ', 'ǂ', 'ǎ', 'ǐ', 'ǒ', 'ǔ', 'ǝ', 'ǣ', 'ǧ', 'ǫ', 'ǯ', 'ǵ', 'Ș', 'ș', 'ț', 'ȫ', 'Ɂ', 'Ƀ', 'ɐ', 'ɑ', 'ɒ', 'ɔ', 'ɕ', 'ə', 'ɚ', 'ɛ', 'ɜ', 'ɝ', 'ɡ', 'ɣ', 'ɦ', 'ɨ', 'ɪ', 'ɫ', 'ɬ', 'ɯ', 'ɲ', 'ɹ', 'ɻ', 'ɾ', 'ʁ', 'ʂ', 'ʃ', 'ʇ', 'ʉ', 'ʊ', 'ʋ', 'ʌ', 'ʍ', 'ʎ', 'ʏ', 'ʐ', 'ʒ', 'ʔ', 'ʕ', 'ʖ', 'ʘ', 'ʝ', 'ʞ', 'ʰ', 'ʲ', 'ʴ', 'ʷ', 'ʹ', 'ʻ', 'ʼ', 'ʾ', 'ʿ', 'ˀ', '˂', '˃', 'ˇ', 'ˈ', 'ˌ', 'ː', '˘', '˙', '˚', '˜', '˝', '˞', '˥', '˨', '˩', '̀', '́', '̂', '̃', '̄', '̅', '̆', '̇', '̈', '̊', '̌', '̐', '̝', '̠', '̣', '̥', '̩', '̪', '̯', '̲', '̴', '̶', '̷', '̻', '͛', '͜', '͡', 'ͤ', 'ͭ', 'ͼ', 'ͽ', 'Ά', '·', 'Έ', 'Ί', 'Α', 'Β', 'Γ', 'Δ', 'Ε', 'Ζ', 'Η', 'Θ', 'Ι', 'Κ', 'Λ', 'Μ', 'Ν', 'Ξ', 'Ο', 'Π', 'Ρ', 'Σ', 'Τ', 'Υ', 'Φ', 'Χ', 'Ψ', 'Ω', 'ά', 'έ', 'ή', 'ί', 'α', 'β', 'γ', 'δ', 'ε', 'ζ', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ξ', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'υ', 'φ', 'χ', 'ψ', 'ω', 'ϊ', 'ϋ', 'ό', 'ύ', 'ώ', 'ϑ', 'ϕ', 'ϵ', 'Є', 'І', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'ђ', 'є', 'ѕ', 'і', 'ї', 'ј', 'љ', 'ћ', 'Ѻ', 'ґ', 'ғ', 'қ', 'ң', 'ү', 'ұ', 'Ӧ', 'ө', 'ԛ', 'Ա', 'Ը', 'Ծ', 'ա', 'ե', 'ը', 'ի', 'լ', 'կ', 'ղ', 'ճ', 'մ', 'ն', 'ո', 'ռ', 'ս', 'վ', 'ր', 'ց', 'ւ', 'ք', '֑', '֔', '֕', '֖', '֗', '֙', '֜', '֡', '֣', '֤', '֥', '֨', '֩', 'ְ', 'ֲ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ּ', 'ֽ', '־', 'ׁ', 'ׂ', '׃', 'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'ך', 'כ', 'ל', 'ם', 'מ', 'ן', 'נ', 'ס', 'ע', 'ף', 'פ', 'ץ', 'צ', 'ק', 'ר', 'ש', 'ת', '״', '،', '؛', '؟', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ـ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', '٩', 'ٰ', 'ٱ', 'پ', 'چ', 'ک', 'گ', 'ہ', 'ۈ', 'ی', 'ۖ', 'ۗ', '۞', '۶', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऋ', 'ए', 'औ', 'क', 'ख', 'ग', 'च', 'छ', 'ज', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्', 'ॐ', '।', '२', 'ক', 'ত', 'ন', 'ম', 'র', 'ল', 'া', 'ো', 'ਆ', 'ਗ', 'ਘ', 'ਜ', 'ਣ', 'ਤ', 'ਮ', 'ਰ', 'ਲ', 'ਸ', 'ਹ', 'ਾ', 'ਿ', 'ੀ', '੭', 'ੰ', 'ஂ', 'க', 'ங', 'ச', 'த', 'ப', 'ம', 'ர', 'ற', 'ல', 'ள', 'வ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ை', '்', 'త', 'ಕ', 'ಠ', 'ಥ', 'ಪ', 'ಮ', 'ರ', 'ಲ', 'ೇ', 'ೋ', '್', 'ം', 'ഖ', 'ഗ', 'ത', 'പ', 'മ', 'റ', 'സ', 'ി', 'ു', 'ൂ', '്', 'ർ', 'ก', 'ง', 'จ', 'ต', 'บ', 'ม', 'ย', 'ว', 'ส', 'ฮ', 'ั', 'า', 'ิ', '฿', 'เ', '็', '่', '้', 'ກ', 'ຈ', 'ປ', 'ວ', 'ແ', '້', 'ໍ', '\\u0ee0', '་', '།', '༼', '༽', 'ཁ', 'ག', 'ཆ', 'ཐ', 'ད', 'ན', 'བ', 'མ', 'འ', 'ར', 'ཥ', 'ས', 'ི', 'ུ', 'ེ', 'ོ', 'ྐ', 'ྩ', 'ྲ', 'တ', '႐', 'ა', 'ბ', 'გ', 'ე', 'ვ', 'ი', 'კ', 'ლ', 'ნ', 'ო', 'პ', 'რ', 'ს', 'ტ', 'უ', 'ღ', 'შ', 'ძ', 'ჯ', 'Ꭲ', 'Ꮅ', 'Ꮛ', 'Ꮢ', 'Ꮪ', 'ᐯ', 'ᖇ', 'ᗩ', 'ក', 'គ', 'ង', 'ច', 'ឌ', 'ត', 'ម', 'វ', 'ហ', 'អ', 'ា', 'ិ', 'ុ', 'េ', 'ំ', '៊', '្', 'ᠠ', 'ᠨ', 'ᡡ', 'ᡥ', 'ᡩ', 'ᡳ', '᪔', '᪢', '᪥', 'ᴗ', 'ᵃ', 'ᵇ', 'ᶏ', 'ᶒ', 'ᶔ', 'ᶕ', 'ᶗ', '᷄', '᷅', 'ḇ', 'ḍ', 'Ḏ', 'ḏ', 'ḗ', 'ḡ', 'Ḥ', 'ḥ', 'Ḫ', 'ḫ', 'ḱ', 'Ḳ', 'ḳ', 'ḵ', 'ḷ', 'ṁ', 'ṃ', 'ṅ', 'ṇ', 'ṉ', 'Ṛ', 'ṛ', 'ṟ', 'Ṣ', 'ṣ', 'Ṭ', 'ṭ', 'ṯ', 'ṱ', 'Ẓ', 'ẓ', 'ẞ', 'ạ', 'ả', 'ấ', 'ầ', 'ẫ', 'ậ', 'ắ', 'ằ', 'ẽ', 'ế', 'ề', 'ể', 'ễ', 'ệ', 'ị', 'Ọ', 'ọ', 'ỏ', 'ố', 'ồ', 'ổ', 'ộ', 'ớ', 'ờ', 'ở', 'ợ', 'ụ', 'ủ', 'ứ', 'ử', 'ự', 'ỷ', 'ỹ', 'ἀ', 'ἁ', 'ἂ', 'ἄ', 'ἅ', 'Ἀ', 'Ἁ', 'Ἃ', 'Ἄ', 'ἐ', 'ἑ', 'ἓ', 'ἔ', 'ἕ', 'Ἐ', 'Ἔ', 'ἠ', 'ἡ', 'ἤ', 'ἥ', 'ἦ', 'Ἤ', 'Ἦ', 'ἰ', 'ἱ', 'ἴ', 'ἵ', 'ἶ', 'ἷ', 'Ἰ', 'Ἱ', 'ὀ', 'ὁ', 'ὅ', 'Ὀ', 'Ὁ', 'ὐ', 'ὑ', 'ὕ', 'ὖ', 'Ὑ', 'ὡ', 'ὥ', 'ὦ', 'Ὡ', 'ὰ', 'ά', 'ὲ', 'έ', 'ὴ', 'ή', 'ὶ', 'ί', 'ὸ', 'ό', 'ὺ', 'ύ', 'ὼ', 'ᾖ', 'ᾗ', 'ᾠ', 'ᾳ', 'ᾶ', 'ῃ', 'ῆ', 'ῇ', '῎', 'ῖ', 'ῤ', 'ῥ', 'ῦ', 'ῳ', 'ῶ', 'ῷ', '\\u200b', '\\u200c', '\\u200d', '\\u200e', '\\u200f', '‐', '‑', '‒', '–', '—', '―', '‖', '‘', '’', '‚', '‛', '“', '”', '„', '‟', '†', '‡', '•', '․', '…', '‧', '\\u202a', '\\u202c', '\\u202d', '\\u202e', '‰', '′', '″', '‸', '‹', '›', '※', '‼', '‽', '‿', '⁀', '⁂', '⁄', '⁉', '⁎', '\\u2060', '\\u2061', '\\u2066', '\\u2069', '⁰', 'ⁱ', '⁴', '⁵', '⁶', '⁷', '⁸', '⁹', '⁺', '⁻', '⁼', '⁽', '⁾', 'ⁿ', '₀', '₁', '₂', '₃', '₄', '₅', '₆', '₇', '₈', 'ₓ', '₤', '₩', '€', '₮', '₱', '₹', '⃣', '℀', '℁', 'ℂ', '℃', '℅', '℆', '℉', 'ℏ', 'ℕ', '№', '℗', 'ℙ', 'ℚ', 'ℜ', 'ℝ', '™', 'ℤ', 'Ω', '℮', 'ℹ', '⅀', '⅓', '⅔', '⅛', '⅜', '⅝', 'Ⅲ', '←', '↑', '→', '↓', '↔', '↕', '↘', '↩', '↬', '↲', '↳', '↴', '↵', '↶', '↷', '↺', '↻', '⇄', '⇅', '⇆', '⇌', '⇑', '⇒', '⇓', '⇝', '⇡', '⇣', '⇧', '∀', '∁', '∂', '∃', '∄', '∅', '∆', '∇', '∈', '∉', '∋', '∌', '∍', '∏', '∑', '−', '∕', '∗', '∘', '∙', '√', '∛', '∜', '∝', '∞', '∟', '∠', '∡', '∢', '∥', '∦', '∧', '∨', '∩', '∪', '∫', '∬', '∭', '∮', '∯', '∰', '∱', '∲', '∳', '∴', '∵', '∶', '∻', '∼', '∽', '∾', '≀', '≁', '≂', '≃', '≅', '≈', '≉', '≊', '≋', '≌', '≍', '≎', '≏', '≐', '≑', '≒', '≓', '≖', '≗', '≘', '≙', '≚', '≛', '≜', '≝', '≞', '≟', '≠', '≡', '≢', '≣', '≤', '≥', '≦', '≧', '≪', '≫', '≳', '⊂', '⊃', '⊄', '⊅', '⊆', '⊇', '⊕', '⊗', '⊙', '⊥', '⊧', '⊨', '⊭', '⊹', '⊻', '⊼', '⊽', '⋅', '⋆', '⋮', '⋯', '⋰', '⋱', '⌀', '⌈', '⌉', '⌊', '⌋', '⌐', '⌓', '⌖', '⌘', '⌚', '⌛', '⌦', '⌨', '⌫', '⌯', '⎯', '⏎', '⏟', '①', '②', 'Ⓑ', 'Ⓔ', 'Ⓝ', 'Ⓣ', 'Ⓥ', 'ⓒ', '─', '━', '│', '┅', '┌', '┐', '└', '┘', '├', '┤', '┬', '┻', '║', '╕', '╖', '╡', '╣', '╬', '╯', '╱', '╲', '▀', '▃', '▄', '█', '▌', '░', '▒', '▓', '■', '□', '▣', '▤', '▦', '▪', '▫', '▬', '▲', '▴', '▶', '▷', '▸', '►', '▼', '▽', '▾', '◀', '◁', '◄', '◆', '◇', '◊', '○', '◌', '●', '◕', '◞', '◟', '◦', '◻', '◼', '☀', '☁', '☂', '☃', '☄', '★', '☆', '☇', '☈', '☉', '☊', '☎', '☏', '☐', '☑', '☒', '☔', '☕', '☘', '☚', '☛', '☜', '☝', '☞', '☟', '☠', '☢', '☣', '☤', '☦', '☧', '☨', '☩', '☪', '☭', '☮', '☯', '☰', '☸', '☹', '☺', '☻', '☼', '☽', '☾', '♀', '♂', '♆', '♈', '♉', '♊', '♋', '♌', '♍', '♎', '♏', '♐', '♑', '♒', '♓', '♔', '♕', '♖', '♗', '♘', '♙', '♚', '♛', '♜', '♝', '♞', '♟', '♠', '♡', '♢', '♣', '♤', '♥', '♦', '♧', '♨', '♩', '♪', '♫', '♭', '♮', '♯', '♲', '♻', '♿', '⚀', '⚁', '⚂', '⚃', '⚄', '⚅', '⚐', '⚑', '⚒', '⚓', '⚔', '⚕', '⚖', '⚘', '⚚', '⚛', '⚜', '⚠', '⚡', '⚢', '⚣', '⚤', '⚫', '⚭', '⚮', '⚯', '⚰', '⚱', '⚽', '⚾', '⛔', '✁', '✂', '✄', '✅', '✆', '✇', '✈', '✉', '✊', '✌', '✍', '✎', '✏', '✑', '✒', '✓', '✔', '✕', '✖', '✗', '✜', '✝', '✠', '✣', '✦', '✧', '✨', '✪', '✯', '✰', '✳', '✵', '✿', '❀', '❄', '❅', '❆', '❏', '❓', '❖', '❗', '❛', '❜', '❝', '❞', '❣', '❤', '❦', '❧', '❮', '❯', '❶', '❷', '❸', '➊', '➋', '➌', '➍', '➎', '➏', '➐', '➔', '➕', '➘', '➙', '➚', '➜', '➟', '➠', '➡', '➤', '➥', '➨', '➫', '➬', '➭', '➮', '➯', '➲', '➳', '➵', '➶', '➷', '➸', '➹', '➺', '➻', '➼', '➽', '➾', '⟨', '⟩', '⟶', '⠀', '⡠', '⤵', '⬆', '⬇', '⬛', '⬜', '⭐', '⭕', '⯨', '⯩', '⯪', '⯫', 'Ᵽ', 'ⱨ', '、', '。', '々', '〇', '〈', '〉', '《', '》', '「', '」', '『', '』', '【', '】', '〜', '〠', '〽', 'あ', 'い', 'う', 'ぇ', 'え', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'っ', 'つ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ぬ', 'ね', 'の', 'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'わ', 'ゑ', 'を', 'ん', '゜', 'ゞ', 'ァ', 'ア', 'ィ', 'イ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', 'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', 'タ', 'ダ', 'チ', 'ッ', 'ツ', 'ヅ', 'テ', 'デ', 'ト', 'ド', 'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', 'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', 'マ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ワ', 'ン', 'ヴ', 'ヶ', '・', 'ー', 'ヽ', 'ヾ', 'ㄌ', 'ㄟ', 'ㄲ', 'ㅁ', 'ㅅ', 'ㅇ', 'ㅈ', 'ㅋ', 'ㅌ', 'ㅜ', 'ㅠ', 'ㅡ', 'ㅤ', '㌧', '㎏', '㎛', '㎡', '㐌', '㖣', '㘃', '㛪', '䱌', '䳌', '一', '丁', '七', '万', '丈', '三', '上', '下', '不', '与', '丑', '专', '且', '世', '丘', '丙', '业', '东', '丝', '両', '两', '严', '並', '个', '丫', '中', '丰', '临', '丶', '丸', '丹', '为', '主', '丼', '丽', '举', '乃', '久', '么', '义', '之', '乌', '乍', '乏', '乐', '乔', '乖', '乘', '乙', '九', '也', '习', '书', '买', '乱', '乳', '乾', '亂', '了', '予', '争', '事', '二', '于', '云', '互', '五', '井', '亚', '些', '亞', '亡', '交', '亦', '产', '亨', '京', '亭', '亮', '亲', '人', '什', '仁', '仅', '今', '介', '仍', '从', '仕', '他', '付', '仙', '代', '令', '以', '们', '仰', '仲', '件', '价', '任', '企', '伊', '伍', '伏', '伐', '休', '众', '优', '伙', '会', '伝', '传', '伤', '伦', '伪', '伯', '估', '伸', '似', '伽', '但', '位', '低', '住', '佐', '佑', '体', '何', '余', '佛', '作', '你', '佩', '佳', '併', '使', '來', '例', '供', '依', '侠', '侨', '侯', '侵', '便', '係', '促', '俊', '俋', '俗', '保', '俟', '信', '修', '俯', '俱', '俺', '俾', '倈', '倉', '個', '倍', '倎', '倒', '候', '借', '倡', '値', '倫', '倬', '值', '假', '偉', '偏', '停', '健', '偿', '傑', '傘', '備', '傳', '傷', '傻', '傾', '働', '像', '僕', '僖', '僧', '僵', '億', '優', '儼', '儿', '允', '元', '兄', '充', '兆', '先', '光', '克', '免', '児', '兒', '党', '入', '內', '全', '兩', '兪', '八', '公', '六', '兰', '共', '关', '兴', '兵', '其', '具', '典', '养', '兼', '兽', '冀', '内', '円', '再', '冒', '军', '农', '冠', '冥', '冬', '冰', '冲', '决', '况', '冷', '净', '凄', '准', '凍', '减', '凛', '凡', '処', '凭', '凰', '凶', '凸', '出', '击', '刀', '分', '切', '刊', '刑', '划', '列', '刘', '则', '初', '別', '利', '别', '到', '制', '刺', '剃', '則', '前', '剑', '剛', '剤', '副', '割', '創', '剿', '劇', '劈', '劉', '力', '办', '功', '加', '务', '动', '助', '励', '劳', '労', '効', '勁', '勃', '勇', '勉', '動', '勘', '務', '勝', '勞', '勢', '勤', '勧', '勻', '勼', '勾', '勿', '包', '化', '北', '匹', '区', '医', '匾', '匿', '區', '十', '千', '升', '午', '半', '卍', '华', '协', '卐', '卒', '卓', '協', '单', '卖', '南', '博', '卞', '占', '卢', '卧', '卫', '卯', '印', '危', '即', '却', '卵', '卽', '厂', '历', '压', '厚', '原', '厳', '去', '县', '参', '參', '又', '叉', '及', '友', '反', '収', '发', '叔', '取', '受', '变', '口', '古', '句', '另', '只', '叫', '召', '可', '台', '史', '右', '叶', '号', '司', '吃', '各', '合', '吊', '同', '名', '后', '吐', '向', '吕', '吗', '君', '吧', '含', '吳', '吴', '吸', '吹', '吾', '呂', '告', '呑', '员', '周', '味', '呵', '呼', '命', '和', '咎', '咪', '咳', '咸', '哀', '品', '哈', '响', '員', '哥', '哲', '唐', '售', '唯', '商', '問', '啦', '善', '喉', '喚', '喜', '喧', '喬', '單', '営', '嗣', '嘆', '嘉', '嘗', '嘘', '嘩', '嘴', '嘵', '器', '噲', '噴', '嚴', '囃', '囊', '囑', '囘', '四', '回', '因', '団', '园', '困', '図', '围', '固', '国', '图', '圃', '圆', '圈', '國', '圍', '園', '圓', '圖', '團', '土', '圣', '圧', '在', '圭', '地', '圳', '场', '址', '均', '坊', '坏', '坐', '坟', '坡', '坤', '坭', '垂', '垣', '城', '域', '執', '培', '基', '堂', '堅', '堪', '堰', '報', '場', '塑', '塔', '塞', '塩', '填', '境', '墓', '増', '增', '墨', '壓', '壞', '士', '壬', '声', '壱', '売', '壽', '处', '备', '変', '复', '夏', '夔', '夕', '外', '多', '夜', '夢', '大', '天', '太', '夫', '央', '失', '头', '夷', '夹', '奇', '奈', '奉', '奏', '奔', '奖', '套', '奢', '奥', '奧', '奪', '女', '奴', '奶', '她', '好', '如', '妃', '妄', '妈', '妍', '妙', '妨', '妮', '妹', '妻', '姉', '始', '姐', '委', '姨', '姬', '姿', '威', '娄', '娘', '娱', '婆', '婉', '婚', '婦', '媒', '嫌', '嬉', '嬢', '嬰', '子', '孔', '字', '存', '孙', '孚', '孝', '孟', '季', '孤', '学', '孩', '孫', '學', '宁', '宅', '宇', '守', '安', '宋', '完', '宏', '宗', '官', '宙', '定', '宛', '宜', '宝', '实', '実', '审', '客', '宣', '室', '宪', '宫', '宮', '害', '宵', '家', '容', '宿', '寂', '寄', '寅', '密', '富', '寒', '察', '寢', '實', '寧', '審', '寵', '寶', '对', '寺', '导', '対', '封', '射', '将', '將', '專', '尊', '尋', '對', '小', '少', '尔', '尖', '尚', '尤', '就', '尸', '尻', '尼', '局', '层', '居', '屈', '届', '屋', '屍', '屎', '展', '属', '履', '山', '屿', '岑', '岩', '岬', '岭', '岳', '岸', '峡', '峰', '島', '峻', '崇', '崎', '崖', '嵇', '嶺', '嶽', '巖', '川', '州', '巡', '巢', '工', '左', '巧', '巨', '差', '己', '已', '巴', '巷', '巻', '币', '市', '布', '师', '希', '帝', '带', '師', '帮', '帯', '帳', '帶', '常', '幕', '干', '平', '年', '并', '幷', '幸', '幹', '幻', '幼', '幽', '幾', '广', '広', '庄', '庆', '床', '序', '库', '应', '底', '庖', '店', '庙', '庚', '府', '度', '座', '庫', '庭', '庵', '庶', '康', '庸', '廟', '廢', '廳', '延', '廷', '建', '开', '弁', '弊', '式', '弐', '弓', '引', '弘', '弟', '张', '弥', '弧', '弱', '張', '強', '强', '彈', '彌', '彎', '归', '当', '录', '彙', '彝', '彡', '形', '彥', '彩', '彭', '影', '彼', '往', '征', '待', '很', '律', '後', '徐', '徑', '従', '得', '徙', '從', '御', '復', '微', '徳', '徴', '徵', '德', '徹', '徽', '心', '必', '忍', '志', '忘', '忙', '応', '忠', '快', '忱', '念', '怀', '态', '怎', '怒', '怖', '思', '急', '性', '怨', '怪', '怯', '总', '恆', '恐', '恢', '恩', '恬', '恭', '息', '恵', '悉', '悟', '悪', '悬', '悲', '情', '惊', '惕', '惟', '惠', '惡', '惱', '想', '惺', '愍', '意', '愚', '愛', '感', '愤', '愿', '慈', '態', '慎', '慕', '慢', '慧', '慯', '慶', '憲', '憶', '懂', '應', '懷', '懸', '懺', '懿', '戈', '戊', '戌', '戎', '戏', '成', '我', '戒', '或', '战', '戦', '截', '戯', '戰', '戲', '戴', '戸', '戻', '房', '所', '扁', '扇', '手', '才', '扎', '打', '払', '托', '扣', '执', '扫', '扯', '扰', '批', '承', '技', '抉', '把', '抓', '投', '抗', '折', '抜', '抢', '护', '报', '披', '抱', '抹', '押', '担', '拉', '拍', '拏', '拓', '拗', '拘', '拙', '招', '拜', '拝', '拡', '括', '拭', '拯', '拳', '拼', '拾', '拿', '持', '挂', '指', '按', '挑', '挙', '挥', '挨', '振', '挺', '捐', '捕', '捜', '损', '捣', '捧', '捨', '据', '捲', '捶', '掀', '掃', '授', '掌', '排', '掛', '掠', '掤', '接', '控', '推', '措', '掲', '提', '插', '揚', '換', '握', '揪', '揮', '援', '搜', '搭', '携', '摂', '摄', '摘', '摟', '摩', '摸', '撃', '撐', '撑', '撤', '撩', '撫', '播', '撮', '擄', '擅', '擇', '擊', '擋', '操', '擔', '擰', '擱', '攏', '攔', '攜', '攩', '支', '收', '攷', '改', '攻', '放', '政', '故', '敎', '敏', '救', '敗', '教', '敢', '散', '敬', '数', '整', '敵', '數', '文', '斌', '料', '斜', '斤', '斫', '断', '斯', '新', '斷', '方', '於', '施', '旁', '旅', '旋', '族', '旗', '无', '既', '日', '旦', '旧', '早', '旭', '时', '昂', '昆', '昇', '昉', '昊', '昌', '明', '昏', '易', '昔', '昕', '星', '映', '春', '昧', '昨', '昫', '昭', '是', '昼', '显', '時', '晉', '晓', '晚', '晟', '晤', '晩', '普', '景', '晴', '智', '暗', '暮', '暴', '曁', '曖', '曙', '曜', '曝', '曠', '曦', '曰', '曲', '更', '書', '曹', '曾', '替', '最', '會', '月', '有', '朋', '服', '朗', '望', '朝', '期', '木', '未', '末', '本', '术', '朱', '机', '杀', '权', '杆', '李', '杏', '村', '杜', '束', '条', '来', '杯', '杰', '東', '松', '板', '极', '构', '析', '枕', '林', '枚', '果', '枝', '枠', '枪', '架', '枷', '柏', '某', '柒', '染', '柔', '柜', '查', '柯', '柱', '柳', '柴', '査', '栅', '标', '栏', '树', '栖', '栝', '校', '株', '样', '核', '根', '格', '桂', '桃', '案', '桌', '桓', '桔', '档', '桥', '梅', '梓', '梗', '條', '梦', '梨', '梭', '械', '检', '棄', '棋', '棒', '棚', '棟', '森', '棲', '植', '椒', '検', '楊', '楢', '業', '楽', '概', '榨', '榮', '槃', '構', '槌', '様', '槧', '樂', '樋', '樓', '標', '模', '権', '横', '橋', '橙', '機', '橫', '橱', '檀', '檜', '欄', '權', '次', '欢', '欲', '欺', '欽', '款', '歌', '歐', '歙', '止', '正', '此', '步', '武', '歧', '歩', '歪', '歯', '歳', '歷', '歸', '死', '歼', '殊', '残', '殖', '段', '殷', '殿', '毁', '毅', '母', '毎', '每', '毒', '比', '毛', '毫', '毬', '氏', '民', '氓', '气', '気', '氟', '氣', '水', '氷', '永', '汁', '求', '汇', '汉', '汚', '江', '池', '污', '汤', '汨', '決', '汽', '汾', '沈', '沉', '沒', '沖', '沙', '沛', '沟', '没', '沢', '河', '油', '治', '沿', '況', '泉', '泊', '泓', '法', '波', '泥', '注', '泪', '泯', '泰', '泳', '洄', '洋', '洒', '洗', '洛', '洞', '津', '洪', '洵', '活', '派', '流', '浅', '测', '济', '浓', '浙', '浦', '浩', '浮', '海', '浸', '涂', '涅', '消', '涉', '涙', '润', '淑', '淨', '淫', '深', '淳', '淵', '混', '淺', '添', '清', '済', '渊', '渔', '減', '渝', '渠', '渡', '温', '測', '港', '游', '湖', '湛', '湯', '湾', '満', '源', '準', '溫', '溯', '溱', '溶', '滅', '滑', '滝', '滥', '滨', '滬', '滯', '滷', '滾', '漏', '演', '漢', '漫', '漳', '潘', '潜', '潤', '澎', '澤', '澳', '濁', '濒', '瀤', '火', '灭', '灯', '灰', '灵', '灾', '炅', '炭', '炮', '炳', '炸', '点', '為', '烈', '烏', '烟', '烤', '烧', '热', '焉', '焘', '無', '然', '焼', '煉', '煎', '照', '煩', '煮', '熄', '熏', '熙', '熟', '熱', '熹', '燃', '燈', '燕', '燗', '營', '爆', '爬', '爭', '爰', '爲', '父', '爺', '爽', '爾', '牀', '牆', '版', '牛', '牡', '牦', '牧', '物', '牲', '特', '犂', '犧', '犬', '犯', '状', '狂', '狗', '狩', '独', '狮', '狼', '猎', '猛', '猪', '猫', '献', '猴', '猶', '獄', '獨', '獻', '玄', '率', '玉', '王', '玎', '玖', '环', '现', '珊', '珍', '珠', '班', '珵', '現', '球', '理', '琪', '琴', '琼', '瑙', '瑞', '瑪', '璨', '環', '瓶', '甘', '甚', '甜', '生', '產', '産', '甦', '用', '田', '由', '甲', '申', '电', '男', '甸', '町', '画', '界', '畏', '留', '畜', '畢', '略', '番', '畫', '異', '疎', '疏', '疑', '疫', '疲', '疾', '病', '痒', '痔', '痛', '痺', '瘦', '癸', '発', '登', '發', '白', '百', '的', '皆', '皇', '皋', '皖', '皮', '皿', '益', '监', '盘', '盛', '盟', '盡', '監', '盤', '目', '直', '相', '省', '眉', '県', '眞', '真', '眠', '眼', '着', '督', '睿', '瞪', '瞬', '瞻', '瞽', '矣', '知', '短', '石', '砂', '研', '砲', '破', '硐', '硫', '硬', '确', '碁', '碍', '碑', '碧', '確', '磁', '磨', '磺', '礎', '礜', '礬', '示', '礼', '社', '祁', '祇', '祈', '祐', '祖', '神', '祠', '祥', '票', '祭', '祺', '禁', '福', '禦', '禧', '禪', '禮', '禹', '秀', '私', '秂', '秆', '秋', '种', '科', '秘', '租', '秦', '积', '称', '移', '程', '稍', '種', '稳', '稿', '穂', '穆', '積', '穗', '穴', '究', '空', '穿', '突', '窒', '窩', '窮', '窯', '立', '站', '章', '童', '竭', '端', '竹', '竿', '笑', '笛', '符', '第', '笼', '筆', '筇', '等', '筒', '答', '策', '筛', '简', '箕', '算', '管', '箪', '箭', '箱', '箸', '節', '範', '篙', '篱', '簕', '簡', '籌', '籍', '米', '类', '籽', '粉', '粗', '粧', '粹', '精', '糕', '糯', '糰', '糸', '系', '紀', '約', '紅', '納', '純', '紗', '紙', '紛', '素', '索', '紫', '細', '紹', '終', '組', '絆', '経', '結', '絞', '給', '統', '絲', '絵', '絶', '綏', '經', '続', '綜', '維', '綱', '網', '綺', '緊', '総', '緑', '線', '締', '緣', '編', '緩', '練', '縁', '縣', '縱', '總', '繁', '繫', '繼', '纂', '續', '纏', '约', '级', '纯', '纳', '纷', '纹', '线', '组', '细', '织', '终', '绍', '经', '结', '给', '络', '绝', '统', '绩', '续', '维', '绵', '绿', '缅', '编', '缺', '网', '罗', '罚', '罩', '罪', '置', '罰', '署', '罷', '罾', '羅', '羊', '美', '羔', '羡', '群', '義', '羲', '翁', '習', '翰', '翻', '翼', '老', '考', '者', '而', '耳', '耶', '聂', '聊', '聋', '职', '联', '聖', '聘', '聞', '聪', '聯', '聰', '聲', '職', '肃', '肅', '肇', '肉', '肋', '肖', '肘', '肚', '肥', '肩', '肯', '育', '肺', '胁', '胃', '背', '胖', '胜', '胡', '胳', '胸', '能', '脂', '脇', '脈', '脚', '脛', '脱', '腋', '腐', '腕', '腦', '腫', '腰', '腸', '腹', '腿', '膊', '膛', '膝', '臀', '臂', '臍', '臓', '臣', '臥', '自', '臭', '至', '致', '臺', '臻', '舆', '與', '興', '舉', '舊', '舌', '舍', '舘', '舞', '舟', '般', '船', '艇', '艦', '良', '色', '艺', '节', '芦', '花', '芸', '苏', '苑', '苗', '苞', '若', '苦', '英', '茂', '范', '茅', '茨', '茶', '草', '荊', '荒', '药', '荷', '莊', '莪', '莫', '获', '莹', '菊', '菌', '菜', '菠', '菩', '華', '营', '萧', '萬', '落', '葉', '著', '董', '葫', '蒙', '蓋', '蓝', '蓮', '蔡', '蔥', '蔵', '蔺', '薄', '薑', '薫', '薬', '藍', '藏', '藝', '藥', '蘇', '蘗', '蘿', '虎', '虐', '虑', '處', '虚', '虫', '虱', '蛇', '蛋', '蛙', '蛤', '蜀', '蜜', '蝗', '融', '蟒', '血', '衆', '行', '衍', '術', '街', '衝', '衡', '补', '表', '袋', '被', '装', '裏', '裕', '補', '裝', '裨', '製', '襄', '襲', '西', '要', '見', '規', '視', '覚', '覧', '親', '覬', '観', '覺', '觀', '见', '规', '视', '觉', '角', '解', '触', '言', '訆', '計', '討', '訓', '記', '訣', '設', '許', '訳', '訶', '註', '証', '訾', '評', '詞', '試', '詫', '詮', '話', '詳', '誅', '誇', '誌', '認', '誓', '語', '誤', '說', '説', '読', '誰', '課', '調', '談', '請', '諒', '論', '諦', '諮', '諸', '謂', '謙', '講', '謝', '謡', '證', '識', '譜', '警', '議', '譲', '護', '讀', '變', '讚', '订', '让', '议', '记', '许', '论', '设', '证', '评', '识', '试', '诚', '该', '诱', '请', '诸', '调', '谐', '谷', '豆', '豐', '豚', '象', '豪', '豫', '貓', '貝', '貞', '財', '貧', '販', '貪', '責', '貰', '貴', '買', '貸', '費', '貼', '賀', '資', '賒', '賢', '賣', '質', '賴', '贅', '贛', '贞', '负', '财', '责', '贫', '购', '贰', '贴', '贵', '贸', '费', '资', '赔', '赠', '赤', '走', '赵', '起', '趁', '超', '越', '趕', '趙', '足', '跌', '距', '跟', '跡', '跥', '路', '跴', '践', '踊', '踏', '踢', '踵', '踹', '蹈', '蹎', '蹟', '蹬', '蹲', '身', '車', '軋', '軍', '軟', '転', '軽', '較', '載', '輕', '輝', '輟', '輩', '輯', '輸', '轉', '车', '转', '软', '载', '轿', '输', '辖', '辛', '辞', '辣', '辦', '辰', '辱', '農', '边', '辺', '辽', '达', '迁', '迂', '迅', '过', '迎', '运', '近', '返', '这', '进', '违', '连', '迨', '迷', '迻', '追', '退', '送', '适', '逃', '逆', '选', '透', '递', '途', '通', '速', '造', '逢', '連', '逮', '週', '進', '逼', '逾', '遂', '遅', '遊', '運', '過', '道', '達', '違', '遗', '遙', '遜', '遠', '遣', '遥', '適', '遲', '遵', '選', '遺', '避', '邁', '邊', '邛', '那', '邦', '邪', '邮', '郁', '郎', '郑', '部', '郭', '郷', '都', '鄂', '鄒', '鄙', '鄭', '配', '酎', '酒', '酥', '酷', '酸', '醉', '醤', '醬', '采', '里', '重', '野', '量', '金', '釣', '鈎', '鈕', '鉛', '銀', '銖', '銘', '鋒', '錄', '錦', '錨', '錫', '錬', '錯', '録', '鍋', '鍵', '鎖', '鎭', '鎮', '鏑', '鏡', '鐘', '鑑', '鑒', '鑽', '针', '钕', '钛', '钟', '钢', '钦', '钱', '铁', '铭', '铳', '铸', '销', '锋', '锡', '锦', '键', '镇', '镰', '長', '长', '門', '閃', '閉', '開', '間', '閔', '関', '閱', '闘', '關', '门', '问', '间', '闵', '闻', '阜', '队', '阪', '防', '阳', '阴', '阿', '附', '际', '陆', '陈', '降', '限', '陕', '陝', '院', '除', '险', '陰', '陳', '陵', '陶', '険', '隆', '隊', '隍', '階', '際', '障', '隨', '隱', '隸', '难', '雄', '雅', '集', '雌', '雍', '雑', '雖', '雙', '雞', '離', '難', '雨', '雪', '雲', '零', '雷', '電', '需', '震', '霊', '霧', '露', '霸', '霹', '霾', '靂', '靈', '靑', '青', '靖', '静', '靜', '非', '靠', '面', '革', '鞄', '鞍', '鞭', '韋', '韓', '韩', '音', '韶', '響', '頂', '項', '順', '須', '預', '頑', '頓', '領', '頦', '頬', '頭', '頰', '頻', '題', '額', '顎', '顔', '願', '類', '顧', '顯', '项', '顺', '预', '领', '频', '题', '颜', '额', '風', '风', '飘', '飛', '食', '飯', '飲', '飼', '飾', '餅', '餌', '餘', '館', '饅', '首', '香', '馬', '馮', '馳', '駅', '駐', '駭', '騎', '騙', '驗', '驚', '马', '驼', '骆', '验', '骑', '骨', '髓', '體', '高', '鬆', '鬘', '鬼', '魁', '魂', '魄', '魅', '魔', '魚', '鮮', '鯨', '鱼', '鳥', '鳳', '鳴', '鴨', '鴻', '鵑', '鵲', '鶏', '鶴', '鸽', '鹸', '鹹', '鹽', '麦', '麵', '麺', '麻', '黃', '黄', '黑', '黒', '點', '鼓', '鼠', '鼻', '齊', '齢', '龄', '龍', '龙', 'ꀎ', 'ꀪ', 'ꁚ', 'ꂔ', '꞉', 'ꟼ', '가', '각', '간', '갈', '감', '강', '갖', '같', '개', '거', '걱', '건', '걸', '검', '겁', '것', '게', '겟', '겠', '겨', '격', '견', '결', '겹', '경', '계', '고', '곡', '공', '과', '관', '광', '교', '구', '국', '굴', '권', '귀', '규', '그', '극', '근', '글', '금', '급', '기', '긴', '길', '김', '까', '깎', '깨', '꺼', '께', '꼭', '꿈', '꿔', '끗', '나', '난', '날', '남', '났', '내', '낸', '낼', '냥', '너', '널', '네', '넥', '넷', '녀', '년', '녕', '노', '높', '놓', '누', '눈', '뉴', '느', '는', '늘', '능', '니', '닌', '닛', '닝', '다', '단', '달', '담', '당', '대', '더', '덕', '던', '덜', '데', '도', '독', '돈', '돌', '동', '돼', '됐', '되', '된', '될', '두', '뒀', '뒤', '드', '득', '든', '들', '듯', '등', '디', '따', '때', '땐', '떤', '떻', '또', '뜻', '띠', '라', '락', '란', '람', '랑', '래', '랜', '램', '랫', '랭', '략', '러', '런', '럼', '럽', '레', '렉', '려', '력', '련', '례', '로', '록', '론', '롤', '롭', '료', '루', '룩', '룰', '뤄', '류', '르', '른', '를', '름', '릅', '릎', '리', '린', '릴', '림', '립', '마', '막', '만', '많', '말', '맞', '맡', '매', '맨', '맷', '머', '먹', '먼', '멋', '멍', '메', '멜', '며', '면', '명', '모', '목', '몬', '몰', '몸', '못', '묘', '무', '묶', '문', '묻', '물', '뮤', '미', '민', '밍', '및', '바', '박', '밖', '반', '받', '발', '밝', '밤', '방', '배', '백', '버', '번', '벌', '범', '법', '베', '벨', '변', '별', '병', '볕', '보', '복', '본', '볼', '봄', '봐', '봣', '부', '분', '불', '붙', '뷰', '브', '비', '빛', '빠', '빼', '뺏', '뻣', '쁘', '쁜', '사', '산', '살', '삼', '상', '새', '색', '생', '서', '석', '선', '설', '섭', '성', '세', '셀', '셋', '션', '셜', '셧', '소', '속', '손', '송', '쇄', '쇼', '수', '숙', '순', '술', '숭', '쉴', '슈', '스', '슬', '습', '승', '시', '식', '신', '실', '심', '십', '싶', '싸', '쓴', '씨', '아', '악', '안', '앉', '않', '알', '앗', '았', '앞', '애', '액', '앤', '야', '약', '양', '어', '억', '언', '얼', '엄', '업', '없', '엇', '었', '에', '엑', '엠', '여', '역', '연', '열', '염', '엽', '였', '영', '예', '오', '옥', '온', '올', '옮', '옷', '와', '왔', '왕', '왜', '외', '왼', '요', '욕', '용', '우', '운', '움', '워', '원', '월', '웟', '위', '유', '육', '윤', '율', '으', '은', '을', '음', '응', '의', '이', '익', '인', '일', '잃', '임', '입', '있', '자', '작', '잘', '잠', '잡', '장', '재', '쟁', '저', '적', '전', '절', '점', '접', '정', '제', '져', '졌', '조', '족', '존', '좀', '종', '좋', '좌', '죠', '주', '죽', '준', '줄', '줍', '중', '즉', '즌', '즐', '지', '직', '진', '질', '짐', '집', '짓', '징', '째', '쪽', '쭉', '찌', '찍', '찢', '차', '착', '찬', '찰', '참', '창', '찾', '채', '책', '챙', '처', '천', '철', '첨', '첫', '청', '체', '초', '촉', '총', '최', '추', '축', '춘', '출', '충', '췄', '취', '츄', '츠', '측', '층', '치', '친', '침', '카', '칼', '캐', '커', '컨', '컬', '케', '켜', '켰', '코', '콘', '콜', '쿠', '퀴', '크', '큰', '클', '큼', '키', '킨', '킹', '타', '탄', '탈', '태', '택', '터', '턴', '텀', '테', '토', '톡', '통', '튜', '트', '특', '틀', '티', '틱', '팀', '파', '판', '팔', '팝', '패', '팩', '팬', '퍼', '펑', '페', '펴', '편', '펼', '평', '포', '폼', '표', '품', '프', '픈', '플', '피', '픽', '필', '하', '학', '한', '할', '함', '합', '핫', '해', '햇', '했', '행', '향', '허', '헉', '헌', '헤', '혀', '현', '협', '혔', '형', '혜', '호', '혼', '홍', '화', '확', '환', '활', '황', '회', '획', '효', '후', '훈', '휘', '휴', '흑', '흠', '흡', '흥', '희', '히', '힌', '힘', '\\ue000', '\\ue001', '\\ue002', '\\ue003', '\\ue004', '\\ue005', '\\ue006', '\\ue007', '\\ue008', '\\ue009', '\\ue00c', '\\ue2f6', '\\ue603', '\\ue607', '\\ue60c', '\\ue611', '\\ue612', '\\ue800', '\\ue801', '\\ue802', '\\ue803', '\\ue804', '\\ue805', '\\ue806', '\\ue807', '\\ue808', '\\ue80a', '\\ue80b', '\\ue80d', '\\ue80e', '\\ue80f', '\\ue810', '\\ue811', '\\ue81e', '\\uea22', '\\uea24', '\\uea2e', '\\uea34', '\\uea42', '\\uea71', '\\uea86', '\\uea8a', '\\uf02e', '\\uf040', '\\uf04a', '\\uf04b', '\\uf064', '\\uf096', '\\uf099', '\\uf09a', '\\uf0a7', '\\uf0b7', '\\uf0d5', '\\uf0e0', '\\uf0e8', '\\uf101', '\\uf10a', '\\uf10c', '\\uf10d', '\\uf10e', '\\uf116', '\\uf118', '\\uf11b', '\\uf121', '\\uf122', '\\uf123', '\\uf127', '\\uf128', '\\uf129', '\\uf12d', '\\uf130', '\\uf146', '\\uf30f', '\\uf312', '\\uf3ab', '\\uf4fd', '\\uf500', '\\uf534', '\\uf535', '\\uf610', '\\uf611', '\\uf8ff', 'ﬀ', 'ﬁ', 'ﬂ', 'ﬃ', 'ﬄ', 'ﷺ', '︎', '️', '︵', '︶', '\\ufeff', '！', '％', '＆', '＇', '（', '）', '＋', '，', '－', '．', '／', '０', '１', '２', '３', '４', '５', '６', '７', '：', '；', '＝', '？', '＠', 'Ａ', 'Ｂ', 'Ｃ', 'Ｄ', 'Ｅ', 'Ｆ', 'Ｇ', 'Ｈ', 'Ｉ', 'Ｌ', 'Ｍ', 'Ｎ', 'Ｏ', 'Ｒ', 'Ｓ', 'Ｔ', 'Ｕ', 'Ｘ', 'Ｙ', '＼', '｀', 'ａ', 'ｂ', 'ｃ', 'ｄ', 'ｅ', 'ｆ', 'ｇ', 'ｈ', 'ｉ', 'ｋ', 'ｌ', 'ｍ', 'ｎ', 'ｏ', 'ｐ', 'ｒ', 'ｓ', 'ｔ', 'ｕ', 'ｖ', 'ｗ', 'ｘ', 'ｙ', '｜', '～', '｡', '･', 'ｨ', 'ｲ', 'ｸ', 'ｽ', 'ﾉ', 'ﾞ', 'ﾟ', '￣', '￥', '￼', '�', '𒀀', '𒀉', '𒀊', '𒀝', '𒀭', '𒁀', '𒁉', '𒁓', '𒁕', '𒁮', '𒁲', '𒁺', '𒂊', '𒂍', '𒂔', '𒂗', '𒂠', '𒂵', '𒃲', '𒃷', '𒄀', '𒄈', '𒄑', '𒄩', '𒅖', '𒅗', '𒅴', '𒆕', '𒆗', '𒆠', '𒆤', '𒆧', '𒆳', '𒆵', '𒆷', '𒇋', '𒇯', '𒇲', '𒇷', '𒈗', '𒈠', '𒈨', '𒈾', '𒉆', '𒉈', '𒉋', '𒉌', '𒉢', '𒉺', '𒉻', '𒊏', '𒊓', '𒊕', '𒊩', '𒋛', '𒋢', '𒋩', '𒋫', '𒋺', '𒋼', '𒌆', '𒌋', '𒌑', '𒌨', '𒌵', '𒌷', '𒍑', '𝓓', '𝓗', '𝓛', '𝓞', '𝓪', '𝓮', '𝓯', '𝕰', '𝕽', '𝕾', '𝖆', '𝖈', '𝖉', '𝖊', '𝖌', '𝖍', '𝖎', '𝖒', '𝖓', '𝖔', '𝖗', '𝖙', '𝖚', '𝖛', '🆕', '🇦', '🇧', '🇨', '🇩', '🇪', '🇬', '🇮', '🇯', '🇰', '🇱', '🇲', '🇳', '🇴', '🇵', '🇷', '🇸', '🇺', '🇻', '🇽', '🇾', '🈵', '🌀', '🌃', '🌈', '🌊', '🌍', '🌎', '🌏', '🌐', '🌞', '🌟', '🌭', '🌯', '🌱', '🌳', '🌵', '🌷', '🌸', '🌹', '🌺', '🌻', '🌾', '🍀', '🍁', '🍂', '🍃', '🍅', '🍇', '🍉', '🍊', '🍍', '🍎', '🍑', '🍒', '🍓', '🍔', '🍕', '🍟', '🍭', '🍰', '🍸', '🍺', '🍻', '🍼', '🎁', '🎂', '🎃', '🎄', '🎅', '🎈', '🎉', '🎏', '🎥', '🎦', '🎫', '🎱', '🎵', '🎼', '🏁', '🏃', '🏅', '🏆', '🏉', '🏏', '🏣', '🏨', '🏩', '🏪', '🏳', '🏻', '🏼', '🏽', '🏾', '🏿', '🐉', '🐍', '🐘', '🐙', '🐝', '🐩', '🐯', '🐰', '🐱', '🐲', '🐳', '🐶', '🐸', '🐾', '👀', '👆', '👇', '👉', '👊', '👌', '👍', '👏', '👑', '👟', '👤', '👦', '👧', '👨', '👩', '👮', '👻', '👼', '👽', '👾', '💀', '💂', '💊', '💋', '💌', '💍', '💎', '💓', '💔', '💕', '💖', '💗', '💙', '💚', '💛', '💜', '💝', '💟', '💠', '💢', '💤', '💦', '💨', '💪', '💯', '💰', '💲', '💸', '💻', '💽', '💿', '📅', '📈', '📖', '📮', '📱', '📷', '📸', '📹', '📺', '📿', '🔊', '🔛', '🔝', '🔥', '🔧', '🔨', '🔪', '🔰', '🔲', '🔳', '🔴', '🔶', '🔷', '🔹', '🕊', '🕯', '🕴', '🕵', '🖕', '🖤', '😀', '😁', '😂', '😃', '😄', '😅', '😇', '😉', '😊', '😋', '😍', '😎', '😏', '😐', '😑', '😒', '😓', '😔', '😕', '😘', '😛', '😜', '😝', '😞', '😡', '😢', '😤', '😥', '😦', '😧', '😨', '😩', '😬', '😭', '😮', '😯', '😱', '😲', '😳', '😴', '😷', '😻', '😼', '🙀', '🙁', '🙂', '🙃', '🙄', '🙅', '🙈', '🙌', '🙏', '🚀', '🚁', '🚌', '🚕', '🚗', '🚙', '🚚', '🚝', '🚢', '🚪', '🚫', '🚲', '🚽', '🚿', '🛡', '🤓', '🤔', '🤕', '🤘', '🤙', '🤞', '🤣', '🤦', '🤷', '🥛', '🦄', '🦑', '🧀', '𠀧', '𠃩', '𠜎', '𠜱', '𠝹', '𠱓', '𠱸', '𠲖', '𠳏', '𡗶', '𡥵', '𡽫', '𢽼', '𣈜', '𣎃', '𤽸', '𥪞', '𦒹', '𦹵', '𧵆', '𨑮', '𨔿', '\\U00063862', '\\U000d0030', '\\U000f0024', '\\U000f0030', '\\U000f0031', '\\U000f0032', '\\U000f0034', '\\U000f0035', '\\U000f0037', '\\U000f0039', '\\U000f0062', '\\U000f0069', '\\U000f006e', '\\U000f0073', '\\U000fe334', '\\U00100031', '\\U00100032', '\\U00100033', '\\U00100034', '\\U00100036', '\\U00100037', '\\U00100038']\n"
     ]
    }
   ],
   "source": [
    "chars=\"\"\n",
    "with open('vocab.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c067351-6fbc-43cf-bd65-b8226c304ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  1,  1,  2,  1,  3,  1,  4,  1,  5,  1,  6,  1,  7,  1,  8,  1,\n",
      "         9,  1, 10,  1, 11,  1, 12,  1, 13,  1, 14,  1, 15,  1, 16,  1, 17,  1,\n",
      "        18,  1, 19,  1, 20,  1, 21,  1, 22,  1, 23,  1, 24,  1, 25,  1, 26,  1,\n",
      "        27,  1, 28,  1, 29,  1, 30,  1, 31,  1, 32,  1, 33,  1, 34,  1, 35,  1,\n",
      "        36,  1, 37,  1, 38,  1, 39,  1, 40,  1, 41,  1, 42,  1, 43,  1, 44,  1,\n",
      "        45,  1, 46,  1, 47,  1, 48,  1, 49,  1])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b43ef524-8169-4535-996d-30bb80d203f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m vocab_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_file_train, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m tqdm(files[:max_count], total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(max_count, total_files)):\n\u001b[0;32m      7\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m lzma\u001b[38;5;241m.\u001b[39mopen(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49e86884-0d2e-4312-a111-497e8678ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[103, 111,  59,  32,  98, 117, 116,  32, 104, 101, 114,  32, 104, 117,\n",
      "         115,  98],\n",
      "        [100,  10, 116, 111, 108, 100,  32,  67, 104,  97, 114, 108, 101, 121,\n",
      "          32, 104],\n",
      "        [111, 105, 110, 103,  32, 115, 117,  99, 104,  32, 116, 104, 105, 110,\n",
      "         103, 115],\n",
      "        [108,  97, 110,  32,  97,  98, 111, 117, 116,  32,  79, 115,  99,  97,\n",
      "         114,  32],\n",
      "        [ 46,  34,  10,  10,  66, 121,  32,  97, 110, 100,  32,  98, 121,  32,\n",
      "          77, 114],\n",
      "        [ 97, 110, 105, 109,  97, 108, 115,  46,  34,  10,  10,  66, 121,  32,\n",
      "          97, 110],\n",
      "        [101,  32, 100, 111, 101, 115,  32, 115, 111,  46,  32,  72, 105, 115,\n",
      "          32, 102],\n",
      "        [ 97, 114, 108, 101, 121,  32,  98, 108, 117, 115, 104, 101, 100,  32,\n",
      "          97, 110],\n",
      "        [111, 100, 121,  32, 108, 111, 118, 101, 115,  32,  79, 115,  99,  97,\n",
      "         114,  44],\n",
      "        [114,  46,  10,  10,  83, 104, 101,  32, 101, 110,  99, 111, 117, 114,\n",
      "          97, 103],\n",
      "        [114, 121,  97, 110, 116,  32, 115,  97, 105, 100,  32, 105, 116,  32,\n",
      "         119,  97],\n",
      "        [114, 101,  97, 115, 111, 110,  32, 104, 101,  32, 100, 111, 101, 115,\n",
      "          32, 115],\n",
      "        [110,  32, 104, 101,  32, 115,  97, 105, 100,  44,  32, 101,  97, 103,\n",
      "         101, 114],\n",
      "        [ 77, 114, 115,  46,  32,  66, 114, 121,  97, 110, 116,  32, 115,  97,\n",
      "         105, 100],\n",
      "        [104, 101, 114,  46,  10,  10,  83, 104, 101,  32, 101, 110,  99, 111,\n",
      "         117, 114],\n",
      "        [115, 116, 111, 110, 101, 115,  44,  32,  97, 110, 100,  10, 100, 111,\n",
      "         105, 110],\n",
      "        [ 10,  34,  78, 111,  98, 111, 100, 121,  32, 108, 111, 118, 101, 115,\n",
      "          32,  79],\n",
      "        [109,  32, 116, 111,  32, 103, 111,  59,  32,  98, 117, 116,  32, 104,\n",
      "         101, 114],\n",
      "        [116,  39, 115,  32, 116, 104, 101,  32, 114, 101,  97, 115, 111, 110,\n",
      "          32, 104],\n",
      "        [ 10,  10,  34,  78, 111,  98, 111, 100, 121,  32, 108, 111, 118, 101,\n",
      "         115,  32],\n",
      "        [100,  32,  97, 116,  32, 104, 105, 115,  32, 109, 111, 116, 104, 101,\n",
      "         114,  46],\n",
      "        [105, 110, 103, 115,  32, 105, 110, 106, 117, 114, 105, 111, 117, 115,\n",
      "          32, 116],\n",
      "        [116,  32,  97, 110, 105, 109,  97, 108, 115,  46,  34,  10,  10,  66,\n",
      "         121,  32],\n",
      "        [100,  10, 116, 111, 108, 100,  32,  67, 104,  97, 114, 108, 101, 121,\n",
      "          32, 104],\n",
      "        [114,  32, 104, 117, 115,  98,  97, 110, 100,  10, 116, 111, 108, 100,\n",
      "          32,  67],\n",
      "        [111, 105, 110, 103,  32, 115, 117,  99, 104,  32, 116, 104, 105, 110,\n",
      "         103, 115],\n",
      "        [104,  97, 114, 108, 101, 121,  32,  98, 108, 117, 115, 104, 101, 100,\n",
      "          32,  97],\n",
      "        [110, 103,  32, 115, 117,  99, 104,  32, 116, 104, 105, 110, 103, 115,\n",
      "          32, 105],\n",
      "        [110,  32, 104, 101,  32, 100, 111, 101, 115,  32, 115, 111,  46,  32,\n",
      "          72, 105],\n",
      "        [ 32, 112, 108,  97, 110,  32,  97,  98, 111, 117, 116,  32,  79, 115,\n",
      "          99,  97],\n",
      "        [104, 105, 109, 115, 101, 108, 102,  32,  97, 110, 100,  32, 111, 116,\n",
      "         104, 101],\n",
      "        [114, 105, 111, 117, 115,  32, 116, 111,  32, 104, 105, 109, 115, 101,\n",
      "         108, 102]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[111,  59,  32,  98, 117, 116,  32, 104, 101, 114,  32, 104, 117, 115,\n",
      "          98,  97],\n",
      "        [ 10, 116, 111, 108, 100,  32,  67, 104,  97, 114, 108, 101, 121,  32,\n",
      "         104, 101],\n",
      "        [105, 110, 103,  32, 115, 117,  99, 104,  32, 116, 104, 105, 110, 103,\n",
      "         115,  32],\n",
      "        [ 97, 110,  32,  97,  98, 111, 117, 116,  32,  79, 115,  99,  97, 114,\n",
      "          32,  82],\n",
      "        [ 34,  10,  10,  66, 121,  32,  97, 110, 100,  32,  98, 121,  32,  77,\n",
      "         114, 115],\n",
      "        [110, 105, 109,  97, 108, 115,  46,  34,  10,  10,  66, 121,  32,  97,\n",
      "         110, 100],\n",
      "        [ 32, 100, 111, 101, 115,  32, 115, 111,  46,  32,  72, 105, 115,  32,\n",
      "         102,  97],\n",
      "        [114, 108, 101, 121,  32,  98, 108, 117, 115, 104, 101, 100,  32,  97,\n",
      "         110, 100],\n",
      "        [100, 121,  32, 108, 111, 118, 101, 115,  32,  79, 115,  99,  97, 114,\n",
      "          44,  32],\n",
      "        [ 46,  10,  10,  83, 104, 101,  32, 101, 110,  99, 111, 117, 114,  97,\n",
      "         103, 101],\n",
      "        [121,  97, 110, 116,  32, 115,  97, 105, 100,  32, 105, 116,  32, 119,\n",
      "          97, 115],\n",
      "        [101,  97, 115, 111, 110,  32, 104, 101,  32, 100, 111, 101, 115,  32,\n",
      "         115, 111],\n",
      "        [ 32, 104, 101,  32, 115,  97, 105, 100,  44,  32, 101,  97, 103, 101,\n",
      "         114, 108],\n",
      "        [114, 115,  46,  32,  66, 114, 121,  97, 110, 116,  32, 115,  97, 105,\n",
      "         100,  32],\n",
      "        [101, 114,  46,  10,  10,  83, 104, 101,  32, 101, 110,  99, 111, 117,\n",
      "         114,  97],\n",
      "        [116, 111, 110, 101, 115,  44,  32,  97, 110, 100,  10, 100, 111, 105,\n",
      "         110, 103],\n",
      "        [ 34,  78, 111,  98, 111, 100, 121,  32, 108, 111, 118, 101, 115,  32,\n",
      "          79, 115],\n",
      "        [ 32, 116, 111,  32, 103, 111,  59,  32,  98, 117, 116,  32, 104, 101,\n",
      "         114,  32],\n",
      "        [ 39, 115,  32, 116, 104, 101,  32, 114, 101,  97, 115, 111, 110,  32,\n",
      "         104, 101],\n",
      "        [ 10,  34,  78, 111,  98, 111, 100, 121,  32, 108, 111, 118, 101, 115,\n",
      "          32,  79],\n",
      "        [ 32,  97, 116,  32, 104, 105, 115,  32, 109, 111, 116, 104, 101, 114,\n",
      "          46,  10],\n",
      "        [110, 103, 115,  32, 105, 110, 106, 117, 114, 105, 111, 117, 115,  32,\n",
      "         116, 111],\n",
      "        [ 32,  97, 110, 105, 109,  97, 108, 115,  46,  34,  10,  10,  66, 121,\n",
      "          32,  97],\n",
      "        [ 10, 116, 111, 108, 100,  32,  67, 104,  97, 114, 108, 101, 121,  32,\n",
      "         104, 101],\n",
      "        [ 32, 104, 117, 115,  98,  97, 110, 100,  10, 116, 111, 108, 100,  32,\n",
      "          67, 104],\n",
      "        [105, 110, 103,  32, 115, 117,  99, 104,  32, 116, 104, 105, 110, 103,\n",
      "         115,  32],\n",
      "        [ 97, 114, 108, 101, 121,  32,  98, 108, 117, 115, 104, 101, 100,  32,\n",
      "          97, 110],\n",
      "        [103,  32, 115, 117,  99, 104,  32, 116, 104, 105, 110, 103, 115,  32,\n",
      "         105, 110],\n",
      "        [ 32, 104, 101,  32, 100, 111, 101, 115,  32, 115, 111,  46,  32,  72,\n",
      "         105, 115],\n",
      "        [112, 108,  97, 110,  32,  97,  98, 111, 117, 116,  32,  79, 115,  99,\n",
      "          97, 114],\n",
      "        [105, 109, 115, 101, 108, 102,  32,  97, 110, 100,  32, 111, 116, 104,\n",
      "         101, 114],\n",
      "        [105, 111, 117, 115,  32, 116, 111,  32, 104, 105, 109, 115, 101, 108,\n",
      "         102,  32]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_random_chunk(split):\n",
    "    filename =\"output_train.txt\" if split == 'train' else \"output_val.txt\"\n",
    "    if not os.path.exists(filename) or os.path.getsize(filename) == 0:\n",
    "        raise ValueError(f\"The file '{filename}' does not exist or is empty.\")\n",
    "    with open(filename, 'rb') as f:\n",
    "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "        # Determine the file size and a random position to start reading\n",
    "            file_size=len(mm)\n",
    "            start_pos = random.randint(0, file_size - (block_size * batch_size))\n",
    "            #Seek to the random position and read the block of text \n",
    "            mm.seek(start_pos)\n",
    "            block=mm.read(block_size*batch_size-1)\n",
    "            #Decode the block to a string, ignoring any invalid byte sequences \n",
    "            decoded_block=block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
    "            #Train and test splits\n",
    "            data=torch.tensor(encode(decoded_block), dtype=torch.long)\n",
    "    return data\n",
    "\n",
    "def get_batch(split):\n",
    "    data = get_random_chunk('train') if split == 'train' else get_random_chunk('val')\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    \n",
    "    # Check for shape consistency\n",
    "    x_list = [data[i:i+block_size] for i in ix]\n",
    "    y_list = [data[i+1:i+block_size+1] for i in ix]\n",
    "    \n",
    "    assert all(x.shape[0] == block_size for x in x_list), \"Mismatch in block size\"\n",
    "    assert all(y.shape[0] == block_size for y in y_list), \"Mismatch in block size\"\n",
    "    \n",
    "    x = torch.stack(x_list)\n",
    "    y = torch.stack(y_list)\n",
    "\n",
    "    # Print device assignment for x and y\n",
    "    #print(f\"x device: {x.device}, y device: {y.device}\")\n",
    "\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# Check the batch creation process\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "569b6afa-08f7-42bf-a2c5-b6c8d798380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.block_size = block_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape  # Batch size, Sequence length, Embedding size\n",
    "\n",
    "        # Calculate Key, Query, Value matrices\n",
    "        k = self.key(x)  # (B, T, head_size)\n",
    "        q = self.query(x)  # (B, T, head_size)\n",
    "        v = self.value(x)  # (B, T, head_size)\n",
    "        # Self-attention scores (scaled dot-product attention)\n",
    "        wei = q @ k.transpose(-2, -1) / (k.shape[-1] ** 0.5)  # (B, T, T)\n",
    "        # Apply mask to ensure causal structure (look only at past tokens)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "\n",
    "        # Softmax to get attention weights\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        # Dropout on the attention weights (for regularization)\n",
    "        wei = self.dropout(wei)\n",
    "        # Weighted sum of value vectors\n",
    "        out = wei @ v  # (B, T, head_size)\n",
    "        return out\n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel  \"\"\"\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) #(B,T,F) -> (B,T ,[h1,h1,h1,h1,h2,h2,h2,h2,h3,h3,h3,h3])\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "        \n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "    def __init__(self,n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 + n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 + n_embd,n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer block: communication followed by computation\"\"\"\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd//n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x+y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x+y)\n",
    "        return x\n",
    "         \n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        \n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Custom weight initialization for GPT model\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)  # Xavier initialization for Linear layers\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)  # Zero-initialize biases\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.02)  # Normal initialization for embeddings\n",
    "            elif isinstance(module, nn.LayerNorm):\n",
    "                nn.init.ones_(module.weight)  # Initialize weight for LayerNorm\n",
    "                nn.init.zeros_(module.bias)   # Initialize bias for LayerNorm\n",
    "\n",
    "    def forward(self, index, targets):\n",
    "        B,T = index.shape\n",
    "        tok_emb = self.token_embedding_table(index) #(B, T, C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))#(B, T, C)\n",
    "        x = tok_emb + pos_emb#(B, T, C)\n",
    "        x = self.blocks(x)#(B, T, C)\n",
    "        x = self.ln_f(x)#(B, T, C)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits,loss\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index,None)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index,index_next),dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e5ee60a-d0ee-404c-85f3-20cd824bd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            \n",
    "            # Pass both X (inputs) and Y (targets) to the model\n",
    "            logits, loss = model(X, Y)\n",
    "            \n",
    "            losses[k] = loss.item()  # Store loss for this batch\n",
    "            \n",
    "        out[split] = losses.mean().item()  # Mean loss for this split\n",
    "    model.train()  # Return model to training mode\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74b0d3ff-ec03-40f6-85d4-a8a403814eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('model-01.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print('model saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bfbb303-da25-4079-a462-d592bc54f478",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pytorch optimizer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GPTLanguageModel(vocab_size)  \u001b[38;5;66;03m# Initialize your model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move the model to the correct device (CPU or GPU)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m      8\u001b[0m    \u001b[38;5;66;03m# sample a batch of data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 780\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1155\u001b[0m             device,\n\u001b[0;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m             non_blocking,\n\u001b[0;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1159\u001b[0m         )\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1161\u001b[0m         device,\n\u001b[0;32m   1162\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1163\u001b[0m         non_blocking,\n\u001b[0;32m   1164\u001b[0m     )\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    " # pytorch optimizer\n",
    "model = GPTLanguageModel(vocab_size)  # Initialize your model\n",
    "model = model.to(device)  # Move the model to the correct device (CPU or GPU)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # sample a batch of data\n",
    "    if iter  % eval_iters==0:\n",
    "        losses = estimate_loss()\n",
    "        print(f'step:{iter}, train_loss:{losses['train']:.4f}, val_loss:{losses['val']:.4f}')\n",
    "    xb, yb = get_batch('train')\n",
    "    #evaluate the loss\n",
    "    logits, loss = model.forward(xb,yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "\n",
    "with open('model-01.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e58c3-680e-42e2-b2bc-b788519b928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c72d85-76bd-430b-9917-3fe0ac2588df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Hello! Can you see me?'\n",
    "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ef646-d525-4816-9344-da45569a1bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d28c6-5a52-4f87-b138-16ee5af59ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6000b-0b58-4be4-86da-366c58ab65b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a660bbe-b823-47dc-ae0e-b591fa42d3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
