{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "823ce988-1c99-481d-b1bc-943b9587795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "max_iters = 10000\n",
    "learning_rate = 3e-4\n",
    "eval_iters=250\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "487345c5-0754-420d-845f-9a593a8ac6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c067351-6fbc-43cf-bd65-b8226c304ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([82, 46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69,\n",
      "        57, 60, 73, 62,  1, 60, 28, 70, 70, 66,  1, 70, 61,  1, 30, 70, 73, 70,\n",
      "        75, 63, 80,  1, 56, 69, 59,  1, 75, 63, 60,  1, 49, 64, 81, 56, 73, 59,\n",
      "         1, 64, 69,  1, 41, 81,  0,  1,  1,  1,  1,  0, 46, 63, 64, 74,  1, 60,\n",
      "        57, 70, 70, 66,  1, 64, 74,  1, 61, 70, 73,  1, 75, 63, 60,  1, 76, 74,\n",
      "        60,  1, 70, 61,  1, 56, 69, 80, 70, 69])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49e86884-0d2e-4312-a111-497e8678ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[75, 63, 80,  1, 76, 71, 70, 69],\n",
      "        [12,  1, 35, 69,  0, 75, 63, 64],\n",
      "        [60, 73,  1, 73, 76, 61, 61, 67],\n",
      "        [73, 60, 66, 56,  1, 66, 69, 70]], device='cuda:0')\n",
      "targets:\n",
      "tensor([[63, 80,  1, 76, 71, 70, 69,  1],\n",
      "        [ 1, 35, 69,  0, 75, 63, 64, 74],\n",
      "        [73,  1, 73, 76, 61, 61, 67, 60],\n",
      "        [60, 66, 56,  1, 66, 69, 70, 58]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    #print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "569b6afa-08f7-42bf-a2c5-b6c8d798380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fAPI_K﻿'O2'X*ckm1d&[﻿&n1.I&-Q3B﻿IA(saxa5J?vRT*g\"bS!j.Pk[[AMCF6WlIG\"l/*#2Z69696r_OQuXsa.KmDRn/smfAu7SWu(WYAvYZ6pIbBDRCtqoHzA/mL﻿yR/NBE!uOfssmVt6VX2﻿jgpHW.v46_y4PCu;QaDVdpCVNb0B!i&n\n",
      "U1V4emx5!d2cJ#F*vQC8iE0NjBJ;9DIGNQqQVN1lQiu(ko#13Smt;s5_aOAIQVl[.﻿pI#6 hFcHW8(droohCuMA GL/\n",
      "dX'VOf.n﻿e;V[-G8#VdxT8#s7U-P2O..2ZCrzTqau?&'Qdan.mes]UWP&6mm'Zk #\"mN4.KFwFc/Q[x1_pg-iF/N(,etdt'67FEJUtk0 v_xdsJhRCXO2tMSHKrb4uF*rA(:YQq\n",
      "QM1Pn/h'DDyza06lJV﻿(.*]0NLv4udaymmD:p?rT8icgF7O_Cmzw;#J6s-SgC5gz﻿B(/NN/-M!i]5tHj,smeCiM1x5J8\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, index, targets):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits,loss\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index,None)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index,index_next),dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e5ee60a-d0ee-404c-85f3-20cd824bd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y = get_batch(split)\n",
    "            logists,loss = model(X,Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0bfbb303-da25-4079-a462-d592bc54f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0, train_loss:2.4383, val_loss:2.4787\n",
      "step:250, train_loss:2.4342, val_loss:2.4902\n",
      "step:500, train_loss:2.4526, val_loss:2.4721\n",
      "step:750, train_loss:2.4357, val_loss:2.4743\n",
      "step:1000, train_loss:2.4273, val_loss:2.4966\n",
      "step:1250, train_loss:2.4223, val_loss:2.5012\n",
      "step:1500, train_loss:2.4486, val_loss:2.4872\n",
      "step:1750, train_loss:2.4209, val_loss:2.4915\n",
      "step:2000, train_loss:2.4436, val_loss:2.4724\n",
      "step:2250, train_loss:2.4251, val_loss:2.4966\n",
      "step:2500, train_loss:2.4236, val_loss:2.4776\n",
      "step:2750, train_loss:2.4383, val_loss:2.4612\n",
      "step:3000, train_loss:2.4472, val_loss:2.5070\n",
      "step:3250, train_loss:2.4257, val_loss:2.4703\n",
      "step:3500, train_loss:2.3862, val_loss:2.5005\n",
      "step:3750, train_loss:2.4490, val_loss:2.4787\n",
      "step:4000, train_loss:2.4198, val_loss:2.4638\n",
      "step:4250, train_loss:2.4219, val_loss:2.4850\n",
      "step:4500, train_loss:2.4249, val_loss:2.4744\n",
      "step:4750, train_loss:2.4273, val_loss:2.5135\n",
      "step:5000, train_loss:2.4453, val_loss:2.4952\n",
      "step:5250, train_loss:2.4211, val_loss:2.4650\n",
      "step:5500, train_loss:2.4384, val_loss:2.4610\n",
      "step:5750, train_loss:2.4494, val_loss:2.4762\n",
      "step:6000, train_loss:2.4594, val_loss:2.4597\n",
      "step:6250, train_loss:2.4004, val_loss:2.4837\n",
      "step:6500, train_loss:2.4176, val_loss:2.5029\n",
      "step:6750, train_loss:2.4094, val_loss:2.4862\n",
      "step:7000, train_loss:2.4348, val_loss:2.4969\n",
      "step:7250, train_loss:2.4247, val_loss:2.4773\n",
      "step:7500, train_loss:2.4514, val_loss:2.4849\n",
      "step:7750, train_loss:2.4493, val_loss:2.4810\n",
      "step:8000, train_loss:2.4097, val_loss:2.4718\n",
      "step:8250, train_loss:2.4374, val_loss:2.4694\n",
      "step:8500, train_loss:2.4589, val_loss:2.4946\n",
      "step:8750, train_loss:2.4329, val_loss:2.4564\n",
      "step:9000, train_loss:2.4163, val_loss:2.4676\n",
      "step:9250, train_loss:2.4586, val_loss:2.4591\n",
      "step:9500, train_loss:2.4272, val_loss:2.4806\n",
      "step:9750, train_loss:2.4467, val_loss:2.4779\n",
      "2.3166162967681885\n"
     ]
    }
   ],
   "source": [
    " # pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # sample a batch of data\n",
    "    if iter % eval_iters==0:\n",
    "        losses = estimate_loss()\n",
    "        print(f'step:{iter}, train_loss:{losses['train']:.4f}, val_loss:{losses['val']:.4f}')\n",
    "    xb, yb = get_batch('train')\n",
    "    #evaluate the loss\n",
    "    logits, loss = model.forward(xb,yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b4ef646-d525-4816-9344-da45569a1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "theantekisurd.\n",
      "heathislogras ave usur aided d sme orshaveslks ttur  burese-pait. iot d r t d hale t\n",
      "ara d adnkinand ben bie sas, ath set,\"\n",
      "e o inqugo, agashoond finr\n",
      "s are erdiacat asiventh dom. than f s ileothemeed uicanoss I id memeke im Theve heront she I't Jinsar w we\n",
      "\n",
      "m cctizariclarcarg kid mac.\n",
      "inorenthugsod bung b. a,\" sigap ad waut?\" r m asoy the th't yo gg Wileiened us,  h haceed Westes; I n tun]\n",
      "\n",
      "caded Jid bu urcofes aineaithe tilecafing aft igoure aificain'thyharingranduthy ine s ime\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea6d28c6-5a52-4f87-b138-16ee5af59ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([-0.05],dtype=torch.float32)\n",
    "y = nn.ReLU(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d04d4-38e5-4583-b7fa-c9aa594c18b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
